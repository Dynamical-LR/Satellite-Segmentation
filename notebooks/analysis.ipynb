{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining initial modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "sys.path.append(\"./\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas\n",
    "import albumentations \n",
    "import matplotlib.pyplot as plt \n",
    "from PIL import Image\n",
    "import numpy\n",
    "import typing\n",
    "import warnings\n",
    "import torch \n",
    "from torch import optim\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining data urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# training images and masks\n",
    "\n",
    "train_images_path = \"../data/train/train/images_size_400/\"\n",
    "train_image_masks_path = \"../data/train/train/masks_size_400/\"\n",
    "\n",
    "# train images and masks\n",
    "\n",
    "first_exp_train_urls = [\n",
    "    (\"../data/train/train/images_size_400/\", \"../data/train/train/masks_size_400/\"),\n",
    "    (\"../data/train/train/images_size_500/\", \"../data/train/train/masks_size_500/\"),\n",
    "    (\"../data/train/train/images_size_600/\", \"../data/train/train/masks_size_600/\"),\n",
    "]\n",
    "\n",
    "first_exp_validation_urls = [\n",
    "    (\"../data/train/_extra/images_size_500/\", \"../data/train/_extra/masks_size_500/\"),\n",
    "]\n",
    "\n",
    "\n",
    "second_exp_train_urls = [\n",
    "    (\"../data/train/train/images_size_500/\", \"../data/train/train/masks_size_500/\"),\n",
    "    (\"../data/train/train/images_size_600/\", \"../data/train/train/masks_size_600/\"),\n",
    "    (\"../data/train/train/images_size_700/\", \"../data/train/train/masks_size_700/\"),\n",
    "]\n",
    "\n",
    "second_exp_validation_urls = [\n",
    "    (\"../data/train/train/images_size_600/\", \"../data/train/train/masks_size_600/\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading small batch of images and masks for initial analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_files(file_path: str):\n",
    "    \"\"\"\n",
    "    Function loads files from given 'file_path' source\n",
    "    Args:\n",
    "        - file_path - path, pointing to the files directory\n",
    "        - number_of_files - respective number of files to load\n",
    "    \"\"\"\n",
    "    batch = []\n",
    "    for path in os.listdir(file_path):\n",
    "        try:\n",
    "            full_url = os.path.join(file_path, path)\n",
    "            ext = path.split(\".\")[-1]\n",
    "            if ext in ('jpeg', 'png', 'jpg'):\n",
    "                batch.append(full_url)\n",
    "                \n",
    "        except(FileNotFoundError):\n",
    "            print('file not found: %s' % full_url)\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_experiment_data(urls: typing.Tuple[str]):\n",
    "    \"\"\"\n",
    "    Function loads data for experiment\n",
    "    \n",
    "    urls: (img_url, mask_url) - list of tuples, containing\n",
    "    corresponding images and masks with different resolutions\n",
    "    \"\"\"\n",
    "    imgs, masks = [], []\n",
    "    for img_path, mask_path in urls:\n",
    "    \n",
    "        imgs = load_files(file_path=train_images_path)\n",
    "        masks = load_files(file_path=train_image_masks_path)\n",
    "\n",
    "        imgs.extend(imgs)\n",
    "        masks.extend(masks)\n",
    "    return imgs, masks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading training and validation sets for first experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "f_train_imgs, f_train_masks = load_experiment_data(first_exp_train_urls)\n",
    "f_validation_imgs, f_validation_masks = load_experiment_data(first_exp_validation_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_exp_train_info = pandas.DataFrame(\n",
    "    {\n",
    "        'image': f_train_imgs,\n",
    "        'mask': f_train_masks\n",
    "    }\n",
    ")\n",
    "\n",
    "first_exp_validation_info = pandas.DataFrame(\n",
    "    {\n",
    "        'image': f_validation_imgs,\n",
    "        'mask': f_validation_masks\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading training and validation sets for second experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_train_imgs, s_train_masks = load_experiment_data(first_exp_train_urls)\n",
    "s_validation_imgs, s_validation_masks = load_experiment_data(first_exp_validation_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "second_exp_train_info = pandas.DataFrame(\n",
    "    {\n",
    "        'image': s_train_imgs,\n",
    "        'mask': s_train_masks\n",
    "    }\n",
    ")\n",
    "\n",
    "second_exp_validation_info = pandas.DataFrame(\n",
    "    {\n",
    "        'image': s_validation_imgs,\n",
    "        'mask': s_validation_masks\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing images and masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import typing\n",
    "\n",
    "def visualize_set_of_images(imgs: typing.List, masks: typing.List):\n",
    "    \"\"\"\n",
    "    Function visualizes image for a given\n",
    "    set of data\n",
    "    \"\"\"\n",
    "    _, ax = plt.subplots(ncols=2, nrows=5)\n",
    "    plt.figure(figsize=(30, 30))\n",
    "\n",
    "    for idx in range(5):\n",
    "        \n",
    "        img = Image.open(imgs[idx])\n",
    "        mask = Image.open(masks[idx])\n",
    "        \n",
    "        ax[idx,0].imshow(img)\n",
    "        ax[idx,1].imshow(mask, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing images and masks for training set (first experiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "visualize_set_of_images(f_train_imgs, f_train_masks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing images and masks for validation set (first experiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "visualize_set_of_images(f_validation_imgs, f_validation_masks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Augmentation Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_color_transformations = albumentations.Compose(\n",
    "    [\n",
    "        albumentations.OneOf([\n",
    "            albumentations.ColorJitter(\n",
    "                brightness=0.15,\n",
    "                hue=0.15,\n",
    "                saturation=0.15\n",
    "            ),\n",
    "            albumentations.FancyPCA()\n",
    "        ])\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Datasets for first experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from dataset.dataset import SegmentationDataset \n",
    "\n",
    "f_train_dataset = SegmentationDataset(\n",
    "    imgs=first_exp_train_info['image'].tolist(),\n",
    "    masks=first_exp_train_info['mask'].tolist(),\n",
    "    color_transformations=train_color_transformations\n",
    ")\n",
    "\n",
    "f_validation_dataset = SegmentationDataset(\n",
    "    imgs=first_exp_validation_info['image'].tolist(),\n",
    "    masks=first_exp_validation_info['mask'].tolist(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining datasets for second experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "s_train_dataset = SegmentationDataset(\n",
    "    imgs=second_exp_train_info['image'].tolist(),\n",
    "    masks=second_exp_train_info['mask'].tolist(),\n",
    "    color_transformations=train_color_transformations\n",
    ")\n",
    "\n",
    "s_validation_dataset = SegmentationDataset(\n",
    "    imgs=second_exp_validation_info['image'].tolist(),\n",
    "    masks=second_exp_validation_info['mask'].tolist()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Beginning of experiments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining loss functions and evaluation metrics for experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from losses.losses import DiceLoss, FocalLoss, ComboLoss\n",
    "\n",
    "focal_gamma = 2\n",
    "\n",
    "dice_loss = DiceLoss()\n",
    "focal_loss = FocalLoss(gamma=focal_gamma)\n",
    "\n",
    "combo_loss = ComboLoss(\n",
    "    dice_prop=0.4, \n",
    "    focal_prop=0.6, \n",
    "    focal_gamma=focal_gamma\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-11-24T14:57:51.102136Z",
     "iopub.status.idle": "2023-11-24T14:57:51.103131Z",
     "shell.execute_reply": "2023-11-24T14:57:51.102890Z"
    }
   },
   "source": [
    "### Defining network for experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from networks import unet\n",
    "network = unet.UNet()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-11-24T14:57:51.106199Z",
     "iopub.status.idle": "2023-11-24T14:57:51.107129Z",
     "shell.execute_reply": "2023-11-24T14:57:51.106924Z"
    }
   },
   "source": [
    "### Defining optimizers and learning rate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "learning_rate = 3e-6\n",
    "adam_opt = optim.Adam(params=network.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
    "sgd_opt = optim.SGD(params=network.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining lr scheduling techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.optim import lr_scheduler\n",
    "\n",
    "reduction_gamma = 0.0001\n",
    "step_size = 5\n",
    "patience_epochs = 5\n",
    "\n",
    "adam_step_scheduler = lr_scheduler.StepLR(\n",
    "    optimizer=adam_opt,\n",
    "    step_size=step_size, \n",
    "    gamma=reduction_gamma\n",
    ")\n",
    "\n",
    "sgd_step_scheduler = lr_scheduler.StepLR(\n",
    "    optimizer=sgd_opt,\n",
    "    step_size=step_size, \n",
    "    gamma=reduction_gamma\n",
    ")\n",
    "\n",
    "adam_plateau_scheduler = lr_scheduler.ReduceLROnPlateau(\n",
    "    adam_opt, mode='min', \n",
    "    factor=0.1,\n",
    "    patience=patience_epochs, \n",
    "    min_lr=learning_rate\n",
    ")\n",
    "\n",
    "sgd_plateau_scheduler = lr_scheduler.ReduceLROnPlateau(\n",
    "    sgd_opt, mode='min', \n",
    "    factor=0.1,\n",
    "    patience=patience_epochs, \n",
    "    min_lr=learning_rate\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def pick_best_batch_size(model_size: float, forward_backward_size: float):\n",
    "    \"\"\"\n",
    "    Function returns maximum batch size,\n",
    "    that can be formed based on existing\n",
    "    network and computational capabilities\n",
    "    \n",
    "    Following formula is applied: \n",
    "    max_batch_size = (total_gpu_bytes - model_size) / (forward_backward_size)\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    \n",
    "    model_size - (mb) - size of the model in bytes\n",
    "    forward_backward_size - (mb) - size of the forward and backward passes in bytes\n",
    "    \"\"\"\n",
    "    total_gpu = torch.cuda.get_device_properties(0).total_memory - torch.cuda.memory_allocated(0)\n",
    "    max_batch = (total_gpu - model_size) / (forward_backward_size)\n",
    "    return 2 ** math.floor(numpy.log2(max_batch))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing network trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from network_trainer.network_trainer import NetworkTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainer = NetworkTrainer(\n",
    "    network=network,\n",
    "    optimizer=adam_opt,\n",
    "    lr_scheduler=adam_step_scheduler,\n",
    "    loss_function=focal_loss,\n",
    "    train_device='cuda',\n",
    "    early_stopping_patience=5,\n",
    "    max_epochs=10,\n",
    "    batch_size=32,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "train_loss, train_history = trainer.train(f_train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('training loss for first trainer: %s' % str(f_train_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "plt.plot(numpy.arange(len((f_train_history))), f_train_history)\n",
    "plt.title(\"Training loss for the first experiment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "f_eval_metric = trainer.evaluate(f_validation_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fg, ax = plt.subplots(ncols=2, nrows=5, figsize=(20, 30))\n",
    "for idx in range(5):\n",
    "    img, mask = f_validation_dataset[0]\n",
    "    predicted_mask = trainer.predict([img])[0]\n",
    "    ax[idx, 0].imshow(predicted_mask.squeeze(0).squeeze(0), cmap='gray')\n",
    "    ax[idx, 1].imshow(mask, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('evaluation metric f1-score for first trainer: %s' % str(f_eval_metric))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Converting model to ONNX Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_path = \"../final_model/network.onnx\"\n",
    "trainer.save_network(model_path, best_input)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DataSphere Kernel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
